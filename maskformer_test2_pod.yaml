apiVersion: v1
kind: Pod
metadata:
    name: parth-pod-gpu-a100-test2
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: nvidia.com/gpu.product
            operator: In
            values:
            - NVIDIA-A100-SXM4-80GB
            - NVIDIA-A40
            - NVIDIA-A10
            - NVIDIA-A6000
            - NVIDIA-GeForce-RTX-3090

  volumes:

  - name: data
    persistentVolumeClaim:
      claimName: parth-residue
  - name: dshm
    emptyDir:
      medium: Memory
  containers:
  - name: gpu-container
    image: gitlab-registry.nrp-nautilus.io/smatous/ali-pytorch-tensorflow
    command: ["sleep", "infinity"]
    resources:
      limits:
        memory: 32Gi
        cpu: 16
        nvidia.com/gpu: 1
        ephemeral-storage: "1000G"
      requests:
        memory: 32Gi
        cpu: 16
        nvidia.com/gpu: 1
        ephemeral-storage: "1000G"
    volumeMounts:
      - name: data
        mountPath: /root/home/test_data
      - name: dshm
        mountPath: /dev/shm
