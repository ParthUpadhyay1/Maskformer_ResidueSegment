apiVersion: batch/v1
kind: Job
metadata: 
  name: parth-dist-job-maskseg2
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-A100-SXM4-80GB
                - NVIDIA-A10
                - NVIDIA-A6000
                - NVIDIA-GeForce-RTX-3090
                - NVIDIA-GeForce-RTX-2080-Ti
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: parth-residue
      - name: dshm
        emptyDir:
          medium: Memory
      containers:
      - name: gpu-container
        image: gitlab-registry.nrp-nautilus.io/smatous/ali-pytorch-tensorflow
        command: ["/bin/bash", "-c"]
        args: ["cd /root/home/; mkdir project; cd project; pip install albumentations; pip install datasets; pip install transformers; pip install wandb; pip install evaluate; pip install Image; pip install torchvision; git clone https://github.com/ParthUpadhyay1/Maskformer_ResidueSegment.git; cd Maskformer_ResidueSegment/MaskformerJob_Dist_clean; cp finalDistTrainSeg_cp2.py ../..; cd ../..; export WANDB_API_KEY=8c1a56f1ebd7e302fab231ebf293ea0979b35164; torchrun --nproc_per_node=4 --master_addr=localhost --master_port=29500 finalDistTrainSeg_cp2.py"]
        resources:
          limits:
            memory: 64Gi
            cpu: 32
            nvidia.com/gpu: 8
            ephemeral-storage: "1000G"
          requests:
            memory: 64Gi
            cpu: 32
            nvidia.com/gpu: 8
            ephemeral-storage: "1000G"
        volumeMounts:
        - name: data
          mountPath: /root/home/data
        - name: dshm
          mountPath: /dev/shm
      restartPolicy: Never
